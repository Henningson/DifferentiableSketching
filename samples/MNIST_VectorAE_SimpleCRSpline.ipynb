{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sketching AutoEncoder with a Catmull-Rom Spline\n",
    "\n",
    "This notebook demonstrates an autoencoder that predicts both a list of 2d points describing a Catmull-Rom spline. Curves between each possible pair of points (excluding the first an last points which act purely as control points) are drawn into separate rasters before being merged into a single image with a compositing function. Only the encoder network has learnable parameters; the decoder is entirely deterministic, but differentiable.\n",
    "\n",
    "The network is defined below; the number of points can be configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "try:\n",
    "    from dsketch.raster.disttrans import catmull_rom_spline, curve_edt2_bruteforce\n",
    "    from dsketch.raster.raster import exp\n",
    "    from dsketch.raster.composite import softor\n",
    "except:\n",
    "    !pip install git+https://github.com/jonhare/DifferentiableSketching.git\n",
    "    from dsketch.raster.disttrans import catmull_rom_spline, curve_edt2_bruteforce\n",
    "    from dsketch.raster.raster import exp\n",
    "    from dsketch.raster.composite import softor\n",
    "    \n",
    "    \n",
    "class AE(nn.Module):\n",
    "    def __init__(self, npoints=16, hidden=64, sz=28):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        # build the coordinate grid:\n",
    "        r = torch.linspace(-1, 1, sz)\n",
    "        c = torch.linspace(-1, 1, sz)\n",
    "        grid = torch.meshgrid(r, c)\n",
    "        grid = torch.stack(grid, dim=2)\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "\n",
    "        # this is a list of quads of \"connections\" 0-1-2-3, 1-2-3-4, 2-3-4-5, ...\n",
    "        self.coordpairs = torch.stack([torch.arange(0, npoints-3, 1),\n",
    "                                       torch.arange(1, npoints-2, 1),\n",
    "                                       torch.arange(2, npoints-1, 1),\n",
    "                                       torch.arange(3, npoints, 1)], dim=1)\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(sz**2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, npoints*2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, inp, sigma=7e-3):\n",
    "        # the encoding process will flatten the input and\n",
    "        # push it through the encoder networks\n",
    "        bs = inp.shape[0]\n",
    "        x = inp.view(bs, -1)\n",
    "        pts = self.enc(x) #[batch, npoints*2]\n",
    "        pts = pts.view(bs, -1, 2) # expand -> [batch, npoints, 2]\n",
    "\n",
    "        # compute all valid permuations of line start and end points\n",
    "        lines = torch.cat((pts[:,self.coordpairs[:,0]],\n",
    "                           pts[:,self.coordpairs[:,1]],\n",
    "                           pts[:,self.coordpairs[:,2]],\n",
    "                           pts[:,self.coordpairs[:,3]]), dim=-1) #[batch, nlines, 8]\n",
    "\n",
    "        lines = lines.view(-1, 4, 2) # flatten -> [batch * nlines, 4, 2]\n",
    "\n",
    "        # Rasterisation steps\n",
    "        # draw the lines (for every input in the batch)\n",
    "        rasters = exp(curve_edt2_bruteforce(lines, self.grid, 2, 10, cfcn=catmull_rom_spline), sigma) # -> [batch * nlines, 28, 28]\n",
    "        rasters = rasters.view(bs, -1, rasters.shape[-2], rasters.shape[-1]) # then reshape back to images [batch, nlines, rows, cols]\n",
    "\n",
    "        # composite\n",
    "        return softor(rasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a simple test on MNIST and try and train the AE to be able to reconstruct digit images (and of course at the same time perform image vectorisation/autotracing of polylines). Hyperparameters are pretty arbitrary (defaults for Adam; 256 batch size) and the line width is fixed to a value that works well for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(28, 28))\n",
    "    ])\n",
    "trainset = torchvision.datasets.MNIST('/tmp', train=True, transform=transform, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.MNIST('/tmp', train=False, transform=transform, download=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = AE(npoints=16).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "    for images, classes in trainloader:\n",
    "        images = images.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = nn.functional.mse_loss(out, images)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally here's a visualisation of a set of test inputs and their rendered reconstructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(testloader).next()[0][0:64]\n",
    "out = model(batch.to(device))\n",
    "\n",
    "plt.figure()\n",
    "inputs = torchvision.utils.make_grid(batch.unsqueeze(1))\n",
    "plt.title(\"Inputs\")\n",
    "plt.imshow(inputs.permute(1,2,0))\n",
    "\n",
    "plt.figure()\n",
    "outputs = torchvision.utils.make_grid(out.detach().cpu().unsqueeze(1))\n",
    "plt.title(\"Outputs\")\n",
    "plt.imshow(outputs.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
